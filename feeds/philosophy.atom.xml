<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Shangfute's Blog - philosophy</title><link href="http://shangfute.github.com/" rel="alternate"></link><link href="http://shangfute.github.com/feeds/philosophy.atom.xml" rel="self"></link><id>http://shangfute.github.com/</id><updated>2017-09-14T21:16:00+08:00</updated><entry><title>认知论</title><link href="http://shangfute.github.com/recognition.html" rel="alternate"></link><published>2017-09-14T21:16:00+08:00</published><updated>2017-09-14T21:16:00+08:00</updated><author><name>尚福特</name></author><id>tag:shangfute.github.com,2017-09-14:/recognition.html</id><summary type="html">&lt;p&gt;唯理论：从逻辑假设出发，进行推理。形式化方法。知识表示，逻辑推理，符号主义。无法处理不确定性。&lt;/p&gt;
&lt;p&gt;经验论：从经验数据中总结公式。机器学习，深度学习。概率，连接主义。黑盒，不知道根据那些规则进行推理的，无法验证。&lt;/p&gt;
&lt;p&gt;但是机器学习得出的结论，不够理性，无法知道事件之间潜在因果关系。不知道我是否知道，也不知道我是否不知道。我们如何知道我知道，如何知道我们不知道什么。深度学习需要大量训练数据才能工作，但人类只需要少量的sample就可以学到大量知识。&lt;/p&gt;
&lt;p&gt;对概率推理进行建模。因为现在的CPS模型和攻击者模型十分复杂，难以使用数学公式进行建模。特别是对人（控制员和攻击者）的认知模型进行建模。&lt;/p&gt;
&lt;p&gt;混合自动机的可达性分析：已知系统模型和规格的验证问题&lt;/p&gt;</summary><content type="html">&lt;p&gt;唯理论：从逻辑假设出发，进行推理。形式化方法。知识表示，逻辑推理，符号主义。无法处理不确定性。&lt;/p&gt;
&lt;p&gt;经验论：从经验数据中总结公式。机器学习，深度学习。概率，连接主义。黑盒，不知道根据那些规则进行推理的，无法验证。&lt;/p&gt;
&lt;p&gt;但是机器学习得出的结论，不够理性，无法知道事件之间潜在因果关系。不知道我是否知道，也不知道我是否不知道。我们如何知道我知道，如何知道我们不知道什么。深度学习需要大量训练数据才能工作，但人类只需要少量的sample就可以学到大量知识。&lt;/p&gt;
&lt;p&gt;对概率推理进行建模。因为现在的CPS模型和攻击者模型十分复杂，难以使用数学公式进行建模。特别是对人（控制员和攻击者）的认知模型进行建模。&lt;/p&gt;
&lt;p&gt;混合自动机的可达性分析：已知系统模型和规格的验证问题&lt;/p&gt;</content><category term="logic"></category><category term="learn"></category></entry></feed>