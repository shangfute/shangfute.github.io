<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Shangfute's Blog</title><link href="http://shangfute.github.com/" rel="alternate"></link><link href="http://shangfute.github.com/feeds/programming.atom.xml" rel="self"></link><id>http://shangfute.github.com/</id><updated>2016-05-26T23:33:07+08:00</updated><entry><title>Learn Haskell</title><link href="http://shangfute.github.com/haskell.html" rel="alternate"></link><published>2016-05-26T23:33:07+08:00</published><author><name>尚福特</name></author><id>tag:shangfute.github.com,2016-05-26:haskell.html</id><summary type="html">&lt;p&gt;I found an interesting tuturial of Haskell programming language today, and had fun with the magic features of functional programming, lazy evaluation, type system and pattern matching. They are very different from the instructive programming language and very expressive. I want to learn more about how to translate them into lambda calculation. I knew some techniques frome the SICP, but more details about realization need to practice. Maybe I would try to make some contribution to the community.&lt;/p&gt;</summary><category term="functioanl programming"></category><category term="haskell"></category></entry><entry><title>并行架构</title><link href="http://shangfute.github.com/parallel-architechture.html" rel="alternate"></link><published>2016-05-24T22:57:17+08:00</published><author><name>尚福特</name></author><id>tag:shangfute.github.com,2016-05-24:parallel-architechture.html</id><summary type="html">&lt;p&gt;并行架构分为位级并行、指令级并行、数据级并行以及任务级并行。&lt;/p&gt;
&lt;p&gt;我比较关注任务级并行，也就是我们平时常说的多处理器架构。对于多处理器架构还分为两种模型：共享内存模型和分布式内存模型。&lt;/p&gt;
&lt;p&gt;共享内存模型的多处理器架构依靠共享的内存进行通信，其效率一般比较高。而分布式内存模型中每个处理器都有一个本地内存，依靠网络进行通信，效率较低，但是更容易并行化。&lt;/p&gt;</summary><category term="parallization"></category></entry><entry><title>并发与并行</title><link href="http://shangfute.github.com/concurrency-parallization.html" rel="alternate"></link><published>2016-05-23T23:17:23+08:00</published><author><name>尚福特</name></author><id>tag:shangfute.github.com,2016-05-23:concurrency-parallization.html</id><summary type="html">&lt;p&gt;目前，计算机几乎无法离开并行计算的能力，同时编程中还有一个并发的概念。并发与并行看起来都是同时做某事，但实际上存在区别。&lt;/p&gt;
&lt;p&gt;并发指能够同时应对多个任务。并行指同时做多个任务的能力。区别在于一个是“应对”，一个是“做”。“应对”针对问题定义层面，“做”针对解决方法层面。比如，我们可以边看电视边烧饭，同时面临两个任务，是并发。同样可以再请别人帮忙一起做饭，同时解决问题，是并行。&lt;/p&gt;
&lt;p&gt;因此，并发不一定并行解决，并行同样不一定针对并发问题。并发任务在解决时可以按顺序逐一解决，当然也可以同时解决。并行也可以解决非并发的问题，提高计算效率。不过并行能够起作用一定是针对的问题可以转化为并发问题。&lt;/p&gt;</summary><category term="parallization"></category><category term="cocurrency"></category></entry></feed>